from skimage import io, transform, color
import matplotlib.pyplot as plt
from preprocessing import RescaleT, ToTensorLab
import os
import torch
from model.u2net import U2NET # full size version 173.6 MB
import numpy as np
from PIL import Image

from helpers import visualize_img


def preprocess_raw_img(raw_img_array):
    """
    This function preprocesses a raw input array in a way such that it can be fed into the U-2-Net architecture

    :param raw_img_array:
    :return:
    """
    rescaler = RescaleT(320)
    rescaled_img = rescaler(raw_img_array)
    tensor_converter = ToTensorLab(flag=0)
    tensor_img = tensor_converter(rescaled_img)
    tensor_img = tensor_img.unsqueeze(0)

    return tensor_img

def load_neural_net(model_dir):
    print("...load U2NET---173.6 MB")
    net = U2NET(3, 1)
    net.load_state_dict(torch.load(model_dir, map_location=torch.device('cpu')))
    net.eval()
    return net

def normPRED(d):
    ma = torch.max(d)
    mi = torch.min(d)
    dn = (d-mi)/(ma-mi)
    return dn

def resize_img_to_orig(prediction_np, orig_img):
    image = Image.fromarray(prediction_np * 255).convert('RGB')
    image_original = image.resize((orig_img.shape[1], orig_img.shape[0]), resample=Image.BILINEAR)
    return image_original

def mask_to_orig_size(orig_img, rescale, threshold):

    mask_orig_size = np.array(orig_img, dtype=np.float64)
    mask_orig_size /= rescale
    mask_orig_size[mask_orig_size > threshold] = 1
    mask_orig_size[mask_orig_size <= threshold] = 0

    return mask_orig_size

def extract_foreground(mask_orig_size):
    shape = mask_orig_size.shape
    a_layer_init = np.ones(shape=(shape[0], shape[1], 1))
    mul_layer = np.expand_dims(mask_orig_size[:, :, 0], axis=2)
    a_layer = mul_layer * a_layer_init
    rgba_out = np.append(mask_orig_size, a_layer, axis=2)
    return rgba_out

def input_to_rgba_inp(input_arr, rescale):
    input_arr = np.array(input_arr, dtype=np.float64)

    shape = input_arr.shape
    input_arr /= rescale
    a_layer = np.ones(shape=(shape[0], shape[1], 1))
    rgba_inp = np.append(input_arr, a_layer, axis=2)

    return rgba_inp

def u2net_api_call(raw_img_array, model):
    """
    This function takes as input an image array of any size. The goal is to return only the object in the foreground of
    the image.
    Therefore, the raw input image is preprocessed, fed into the deep learning model. Afterwards the foreground of the
    original image is extracted from the mask which was generated by the deep learning model.
    """
    THRESHOLD = 0.9
    RESCALE = 255

    preprocessed_img = preprocess_raw_img(raw_img_array)

    d1, d2, d3, d4, d5, d6, d7 = model(preprocessed_img)

    prediction = d1[:, 0, :, :]
    prediction = normPRED(prediction)
    prediction_np = prediction.squeeze().cpu().data.numpy()


    img_orig_size = resize_img_to_orig(prediction_np, raw_img_array)
    mask_orig_size = mask_to_orig_size(img_orig_size, RESCALE, THRESHOLD)
    rgba_out = extract_foreground(mask_orig_size)
    rgba_inp = input_to_rgba_inp(raw_img_array, RESCALE)
    rem_back = (rgba_inp * rgba_out)

    return rem_back


if __name__=="__main__":
    test_img_path = "/Users/felixasanger/Desktop/background_removal/test_data/test_images/J306P12B__20201116_22-25-33__c0.jpg"
    input_image = io.imread(test_img_path) # <class 'numpy.ndarray'>

    visualize_img(input_image, description_string="Input Image")

    model_name = 'u2net'
    model_dir = os.path.join(os.getcwd(), 'saved_models', model_name, model_name + '.pth')

    model = load_neural_net(model_dir)
    background_removed = u2net_api_call(input_image, model)

    visualize_img(background_removed, description_string="Removed Background")